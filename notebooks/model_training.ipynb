{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Fake Image Detection - Model Training\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook contains the complete pipeline for training deep learning models to detect fake/manipulated images.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries and Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from tqdm import tqdm\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"from PIL import Image\\n\",\n",
    "    \"import albumentations as A\\n\",\n",
    "    \"from albumentations.pytorch import ToTensorV2\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Deep Learning Libraries\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow import keras\\n\",\n",
    "    \"from tensorflow.keras import layers, models, optimizers, callbacks\\n\",\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "    \"\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torch.optim as optim\\n\",\n",
    "    \"from torch.utils.data import Dataset, DataLoader\\n\",\n",
    "    \"import torchvision.transforms as transforms\\n\",\n",
    "    \"import torchvision.models as models\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sklearn\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"from utils.data_preprocessing import *\\n\",\n",
    "    \"from utils.visualization import *\\n\",\n",
    "    \"from utils.metrics import *\\n\",\n",
    "    \"from models.cnn_model import *\\n\",\n",
    "    \"from models.resnet_model import *\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set random seeds for reproducibility\\n\",\n",
    "    \"np.random.seed(42)\\n\",\n",
    "    \"tf.random.set_seed(42)\\n\",\n",
    "    \"torch.manual_seed(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# GPU Configuration\\n\",\n",
    "    \"physical_devices = tf.config.experimental.list_physical_devices('GPU')\\n\",\n",
    "    \"if len(physical_devices) > 0:\\n\",\n",
    "    \"    tf.config.experimental.set_memory_growth(physical_devices[0], True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
    "    \"print(f\\\"Using device: {device}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Configuration and Hyperparameters\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration\\n\",\n",
    "    \"CONFIG = {\\n\",\n",
    "    \"    'DATA_DIR': '../data',\\n\",\n",
    "    \"    'REAL_DIR': '../data/real',\\n\",\n",
    "    \"    'FAKE_DIR': '../data/fake',\\n\",\n",
    "    \"    'TEST_DIR': '../data/test',\\n\",\n",
    "    \"    'MODEL_SAVE_DIR': '../models/saved_models',\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Image parameters\\n\",\n",
    "    \"    'IMG_SIZE': (224, 224),\\n\",\n",
    "    \"    'BATCH_SIZE': 32,\\n\",\n",
    "    \"    'CHANNELS': 3,\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Training parameters\\n\",\n",
    "    \"    'EPOCHS': 50,\\n\",\n",
    "    \"    'LEARNING_RATE': 0.001,\\n\",\n",
    "    \"    'VALIDATION_SPLIT': 0.2,\\n\",\n",
    "    \"    'TEST_SPLIT': 0.1,\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Model parameters\\n\",\n",
    "    \"    'DROPOUT_RATE': 0.5,\\n\",\n",
    "    \"    'L2_REGULARIZATION': 0.01,\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Callbacks\\n\",\n",
    "    \"    'EARLY_STOPPING_PATIENCE': 10,\\n\",\n",
    "    \"    'REDUCE_LR_PATIENCE': 5,\\n\",\n",
    "    \"    'REDUCE_LR_FACTOR': 0.5\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create necessary directories\\n\",\n",
    "    \"os.makedirs(CONFIG['MODEL_SAVE_DIR'], exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Configuration loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Image size: {CONFIG['IMG_SIZE']}\\\")\\n\",\n",
    "    \"print(f\\\"Batch size: {CONFIG['BATCH_SIZE']}\\\")\\n\",\n",
    "    \"print(f\\\"Epochs: {CONFIG['EPOCHS']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Data Loading and Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load and preprocess data\\n\",\n",
    "    \"def load_dataset(real_dir, fake_dir, img_size):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Load images from real and fake directories\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    images = []\\n\",\n",
    "    \"    labels = []\\n\",\n",
    "    \"    filepaths = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load real images (label = 1)\\n\",\n",
    "    \"    real_files = [f for f in os.listdir(real_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\\n\",\n",
    "    \"    print(f\\\"Found {len(real_files)} real images\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for filename in tqdm(real_files, desc=\\\"Loading real images\\\"):\\n\",\n",
    "    \"        filepath = os.path.join(real_dir, filename)\\n\",\n",
    "    \"        img = load_and_preprocess_image(filepath, img_size)\\n\",\n",
    "    \"        if img is not None:\\n\",\n",
    "    \"            images.append(img)\\n\",\n",
    "    \"            labels.append(1)  # Real = 1\\n\",\n",
    "    \"            filepaths.append(filepath)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load fake images (label = 0)\\n\",\n",
    "    \"    fake_files = [f for f in os.listdir(fake_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\\n\",\n",
    "    \"    print(f\\\"Found {len(fake_files)} fake images\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for filename in tqdm(fake_files, desc=\\\"Loading fake images\\\"):\\n\",\n",
    "    \"        filepath = os.path.join(fake_dir, filename)\\n\",\n",
    "    \"        img = load_and_preprocess_image(filepath, img_size)\\n\",\n",
    "    \"        if img is not None:\\n\",\n",
    "    \"            images.append(img)\\n\",\n",
    "    \"            labels.append(0)  # Fake = 0\\n\",\n",
    "    \"            filepaths.append(filepath)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return np.array(images), np.array(labels), filepaths\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load the dataset\\n\",\n",
    "    \"print(\\\"Loading dataset...\\\")\\n\",\n",
    "    \"X, y, filepaths = load_dataset(CONFIG['REAL_DIR'], CONFIG['FAKE_DIR'], CONFIG['IMG_SIZE'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total images loaded: {len(X)}\\\")\\n\",\n",
    "    \"print(f\\\"Real images: {np.sum(y)}\\\")\\n\",\n",
    "    \"print(f\\\"Fake images: {len(y) - np.sum(y)}\\\")\\n\",\n",
    "    \"print(f\\\"Image shape: {X.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Label distribution: {np.bincount(y)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Data Exploration and Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize sample images\\n\",\n",
    "    \"plot_sample_images(X, y, num_samples=8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot class distribution\\n\",\n",
    "    \"plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"labels_text = ['Fake', 'Real']\\n\",\n",
    "    \"counts = np.bincount(y)\\n\",\n",
    "    \"plt.bar(labels_text, counts, color=['red', 'green'], alpha=0.7)\\n\",\n",
    "    \"plt.title('Class Distribution')\\n\",\n",
    "    \"plt.ylabel('Number of Images')\\n\",\n",
    "    \"for i, count in enumerate(counts):\\n\",\n",
    "    \"    plt.text(i, count + 10, str(count), ha='center', va='bottom')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate and display basic statistics\\n\",\n",
    "    \"print(f\\\"\\\\nDataset Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"Total samples: {len(X)}\\\")\\n\",\n",
    "    \"print(f\\\"Image dimensions: {X.shape[1:]}\\\")\\n\",\n",
    "    \"print(f\\\"Pixel value range: [{X.min():.3f}, {X.max():.3f}]\\\")\\n\",\n",
    "    \"print(f\\\"Mean pixel value: {X.mean():.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Std pixel value: {X.std():.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Data Augmentation Setup\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# TensorFlow Data Augmentation\\n\",\n",
    "    \"tf_train_datagen = ImageDataGenerator(\\n\",\n",
    "    \"    rotation_range=20,\\n\",\n",
    "    \"    width_shift_range=0.2,\\n\",\n",
    "    \"    height_shift_range=0.2,\\n\",\n",
    "    \"    horizontal_flip=True,\\n\",\n",
    "    \"    zoom_range=0.2,\\n\",\n",
    "    \"    shear_range=0.1,\\n\",\n",
    "    \"    brightness_range=[0.8, 1.2],\\n\",\n",
    "    \"    validation_split=CONFIG['VALIDATION_SPLIT']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"tf_val_datagen = ImageDataGenerator(\\n\",\n",
    "    \"    validation_split=CONFIG['VALIDATION_SPLIT']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# PyTorch Data Augmentation using Albumentations\\n\",\n",
    "    \"train_transform = A.Compose([\\n\",\n",
    "    \"    A.Resize(CONFIG['IMG_SIZE'][0], CONFIG['IMG_SIZE'][1]),\\n\",\n",
    "    \"    A.HorizontalFlip(p=0.5),\\n\",\n",
    "    \"    A.VerticalFlip(p=0.2),\\n\",\n",
    "    \"    A.Rotate(limit=20, p=0.5),\\n\",\n",
    "    \"    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\\n\",\n",
    "    \"    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\\n\",\n",
    "    \"    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n\",\n",
    "    \"    ToTensorV2()\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_transform = A.Compose([\\n\",\n",
    "    \"    A.Resize(CONFIG['IMG_SIZE'][0], CONFIG['IMG_SIZE'][1]),\\n\",\n",
    "    \"    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n\",\n",
    "    \"    ToTensorV2()\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Data augmentation pipelines created successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Data Splitting\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Split the data\\n\",\n",
    "    \"X_temp, X_test, y_temp, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=CONFIG['TEST_SPLIT'], \\n\",\n",
    "    \"    stratify=y, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_val, y_train, y_val = train_test_split(\\n\",\n",
    "    \"    X_temp, y_temp, test_size=CONFIG['VALIDATION_SPLIT']/(1-CONFIG['TEST_SPLIT']), \\n\",\n",
    "    \"    stratify=y_temp, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set size: {len(X_train)}\\\")\\n\",\n",
    "    \"print(f\\\"Validation set size: {len(X_val)}\\\")\\n\",\n",
    "    \"print(f\\\"Test set size: {len(X_test)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nClass distribution in training set:\\\")\\n\",\n",
    "    \"print(f\\\"Real: {np.sum(y_train)}, Fake: {len(y_train) - np.sum(y_train)}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nClass distribution in validation set:\\\")\\n\",\n",
    "    \"print(f\\\"Real: {np.sum(y_val)}, Fake: {len(y_val) - np.sum(y_val)}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nClass distribution in test set:\\\")\\n\",\n",
    "    \"print(f\\\"Real: {np.sum(y_test)}, Fake: {len(y_test) - np.sum(y_test)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. TensorFlow/Keras Model Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Build CNN Model\\n\",\n",
    "    \"def build_cnn_model(input_shape, num_classes=1):\\n\",\n",
    "    \"    model = models.Sequential([\\n\",\n",
    "    \"        # First Convolutional Block\\n\",\n",
    "    \"        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"        layers.Dropout(0.25),\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Second Convolutional Block\\n\",\n",
    "    \"        layers.Conv2D(64, (3, 3), activation='relu'),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"        layers.Dropout(0.25),\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Third Convolutional Block\\n\",\n",
    "    \"        layers.Conv2D(128, (3, 3), activation='relu'),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"        layers.Dropout(0.25),\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Fourth Convolutional Block\\n\",\n",
    "    \"        layers.Conv2D(256, (3, 3), activation='relu'),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.MaxPooling2D((2, 2)),\\n\",\n",
    "    \"        layers.Dropout(0.25),\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Dense layers\\n\",\n",
    "    \"        layers.Flatten(),\\n\",\n",
    "    \"        layers.Dense(512, activation='relu'),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.Dropout(CONFIG['DROPOUT_RATE']),\\n\",\n",
    "    \"        layers.Dense(256, activation='relu'),\\n\",\n",
    "    \"        layers.Dropout(CONFIG['DROPOUT_RATE']),\\n\",\n",
    "    \"        layers.Dense(num_classes, activation='sigmoid')\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Build the model\\n\",\n",
    "    \"input_shape = (*CONFIG['IMG_SIZE'], CONFIG['CHANNELS'])\\n\",\n",
    "    \"cnn_model = build_cnn_model(input_shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compile the model\\n\",\n",
    "    \"cnn_model.compile(\\n\",\n",
    "    \"    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\\n\",\n",
    "    \"    loss='binary_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy', 'precision', 'recall']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model summary\\n\",\n",
    "    \"cnn_model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup callbacks\\n\",\n",
    "    \"callbacks_list = [\\n\",\n",
    "    \"    callbacks.EarlyStopping(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\\n\",\n",
    "    \"        restore_best_weights=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    callbacks.ReduceLROnPlateau(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        factor=CONFIG['REDUCE_LR_FACTOR'],\\n\",\n",
    "    \"        patience=CONFIG['REDUCE_LR_PATIENCE'],\\n\",\n",
    "    \"        verbose=1,\\n\",\n",
    "    \"        min_lr=1e-7\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    callbacks.ModelCheckpoint(\\n\",\n",
    "    \"        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_cnn_model.h5'),\\n\",\n",
    "    \"        monitor='val_accuracy',\\n\",\n",
    "    \"        save_best_only=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Callbacks configured successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train the CNN model\\n\",\n",
    "    \"print(\\\"Starting CNN model training...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"cnn_history = cnn_model.fit(\\n\",\n",
    "    \"    X_train, y_train,\\n\",\n",
    "    \"    batch_size=CONFIG['BATCH_SIZE'],\\n\",\n",
    "    \"    epochs=CONFIG['EPOCHS'],\\n\",\n",
    "    \"    validation_data=(X_val, y_val),\\n\",\n",
    "    \"    callbacks=callbacks_list,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"CNN model training completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Transfer Learning with ResNet\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Build ResNet-based model\\n\",\n",
    "    \"def build_resnet_model(input_shape, num_classes=1):\\n\",\n",
    "    \"    # Load pre-trained ResNet50\\n\",\n",
    "    \"    base_model = tf.keras.applications.ResNet50(\\n\",\n",
    "    \"        weights='imagenet',\\n\",\n",
    "    \"        include_top=False,\\n\",\n",
    "    \"        input_shape=input_shape\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Freeze base model layers\\n\",\n",
    "    \"    base_model.trainable = False\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add custom layers\\n\",\n",
    "    \"    model = models.Sequential([\\n\",\n",
    "    \"        base_model,\\n\",\n",
    "    \"        layers.GlobalAveragePooling2D(),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.Dropout(0.5),\\n\",\n",
    "    \"        layers.Dense(512, activation='relu'),\\n\",\n",
    "    \"        layers.BatchNormalization(),\\n\",\n",
    "    \"        layers.Dropout(0.3),\\n\",\n",
    "    \"        layers.Dense(256, activation='relu'),\\n\",\n",
    "    \"        layers.Dropout(0.2),\\n\",\n",
    "    \"        layers.Dense(num_classes, activation='sigmoid')\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model, base_model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Build ResNet model\\n\",\n",
    "    \"resnet_model, base_model = build_resnet_model(input_shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compile the model\\n\",\n",
    "    \"resnet_model.compile(\\n\",\n",
    "    \"    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\\n\",\n",
    "    \"    loss='binary_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy', 'precision', 'recall']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model summary\\n\",\n",
    "    \"resnet_model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup callbacks for ResNet\\n\",\n",
    "    \"resnet_callbacks = [\\n\",\n",
    "    \"    callbacks.EarlyStopping(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\\n\",\n",
    "    \"        restore_best_weights=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    callbacks.ReduceLROnPlateau(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        factor=CONFIG['REDUCE_LR_FACTOR'],\\n\",\n",
    "    \"        patience=CONFIG['REDUCE_LR_PATIENCE'],\\n\",\n",
    "    \"        verbose=1,\\n\",\n",
    "    \"        min_lr=1e-7\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    callbacks.ModelCheckpoint(\\n\",\n",
    "    \"        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_resnet_model.h5'),\\n\",\n",
    "    \"        monitor='val_accuracy',\\n\",\n",
    "    \"        save_best_only=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train ResNet model\\n\",\n",
    "    \"print(\\\"Starting ResNet model training...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"resnet_history = resnet_model.fit(\\n\",\n",
    "    \"    X_train, y_train,\\n\",\n",
    "    \"    batch_size=CONFIG['BATCH_SIZE'],\\n\",\n",
    "    \"    epochs=CONFIG['EPOCHS'],\\n\",\n",
    "    \"    validation_data=(X_val, y_val),\\n\",\n",
    "    \"    callbacks=resnet_callbacks,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"ResNet model training completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Fine-tuning ResNet\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Fine-tune the ResNet model\\n\",\n",
    "    \"print(\\\"Starting fine-tuning of ResNet model...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Unfreeze the top layers of the base model\\n\",\n",
    "    \"base_model.trainable = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fine-tune from this layer onwards\\n\",\n",
    "    \"fine_tune_at = 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Freeze all the layers before the `fine_tune_at` layer\\n\",\n",
    "    \"for layer in base_model.layers[:fine_tune_at]:\\n\",\n",
    "    \"    layer.trainable = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Recompile with a lower learning rate\\n\",\n",
    "    \"resnet_model.compile(\\n\",\n",
    "    \"    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']/10),\\n\",\n",
    "    \"    loss='binary_crossentropy',\\n\",\n",
    "    \"    metrics=['accuracy', 'precision', 'recall']\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fine-tune callbacks\\n\",\n",
    "    \"finetune_callbacks = [\\n\",\n",
    "    \"    callbacks.EarlyStopping(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        patience=5,\\n\",\n",
    "    \"        restore_best_weights=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    ),\\n\",\n",
    "    \"    callbacks.ModelCheckpoint(\\n\",\n",
    "    \"        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_resnet_finetuned.h5'),\\n\",\n",
    "    \"        monitor='val_accuracy',\\n\",\n",
    "    \"        save_best_only=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Continue training with fine-tuning\\n\",\n",
    "    \"finetune_epochs = 10\\n\",\n",
    "    \"total_epochs = len(resnet_history.history['loss']) + finetune_epochs\\n\",\n",
    "    \"\\n\",\n",
    "    \"resnet_finetune_history = resnet_model.fit(\\n\",\n",
    "    \"    X_train, y_train,\\n\",\n",
    "    \"    batch_size=CONFIG['BATCH_SIZE'],\\n\",\n",
    "    \"    epochs=total_epochs,\\n\",\n",
    "    \"    initial_epoch=len(resnet_history.history['loss']),\\n\",\n",
    "    \"    validation_data=(X_val, y_val),\\n\",\n",
    "    \"    callbacks=finetune_callbacks,\\n\",\n",
    "    \"    verbose=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Fine-tuning completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. PyTorch Model Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# PyTorch Dataset Class\\n\",\n",
    "    \"class FakeImageDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, images, labels, transform=None):\\n\",\n",
    "    \"        self.images = images\\n\",\n",
    "    \"        self.labels = labels\\n\",\n",
    "    \"        self.transform = transform\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return len(self.images)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        image = self.images[idx]\\n\",\n",
    "    \"        label = self.labels[idx]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if self.transform:\\n\",\n",
    "    \"            # Convert to uint8 for albumentations\\n\",\n",
    "    \"            image = (image * 255).astype(np.uint8)\\n\",\n",
    "    \"            transformed = self.transform(image=image)\\n\",\n",
    "    \"            image = transformed['image']\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            image = torch.FloatTensor(image).permute(2, 0, 1)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return image, torch.FloatTensor([label])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create PyTorch datasets\\n\",\n",
    "    \"train_dataset = FakeImageDataset(X_train, y_train, transform=train_transform)\\n\",\n",
    "    \"val_dataset = FakeImageDataset(X_val, y_val, transform=val_transform)\\n\",\n",
    "    \"test_dataset = FakeImageDataset(X_test, y_test, transform=val_transform)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create data loaders\\n\",\n",
    "    \"train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\\n\",\n",
    "    \"val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False)\\n\",\n",
    "    \"test_loader = DataLoader(test_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"PyTorch datasets created:\\\")\\n\",\n",
    "    \"print(f\\\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# PyTorch ResNet Model\\n\",\n",
    "    \"class PyTorchResNetModel(nn.Module):\\n\",\n",
    "    \"    def __init__(self, num_classes=1):\\n\",\n",
    "    \"        super(PyTorchResNetModel, self).__init__()\\n\",\n",
    "    \"        self.resnet = models.resnet50(pretrained=True)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Freeze early layers\\n\",\n",
    "    \"        for param in self.resnet.parameters():\\n\",\n",
    "    \"            param.requires_grad = False\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Unfreeze last few layers\\n\",\n",
    "    \"        for param in self.resnet.layer4.parameters():\\n\",\n",
    "    \"            param.requires_grad = True\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Replace the classifier\\n\",\n",
    "    \"        num_features = self.resnet.fc.in_features\\n\",\n",
    "    \"        self.resnet.fc = nn.Sequential(\\n\",\n",
    "    \"            nn.Dropout(0.5),\\n\",\n",
    "    \"            nn.Linear(num_features, 512),\\n\",\n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"            nn.BatchNorm1d(512),\\n\",\n",
    "    \"            nn.Dropout(0.3),\\n\",\n",
    "    \"            nn.Linear(512, 256),\\n\",\n",
    "    \"            nn.ReLU(),\\n\",\n",
    "    \"            nn.Dropout(0.2),\\n\",\n",
    "    \"            nn.Linear(256, num_classes),\\n\",\n",
    "    \"            nn.Sigmoid()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        return self.resnet(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize PyTorch model\\n\",\n",
    "    \"pytorch_model = PyTorchResNetModel().to(device)\\n\",\n",
    "    \"criterion = nn.BCELoss()\\n\",\n",
    "    \"optimizer = optim.Adam(pytorch_model.parameters(), lr=CONFIG['LEARNING_RATE'])\\n\",\n",
    "    \"scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"PyTorch model initialized!\\\")\\n\",\n",
    "    \"print(f\\\"Model parameters: {sum(p.numel() for p in pytorch_model.parameters() if p.requires_grad)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# PyTorch training function\\n\",\n",
    "    \"def train_pytorch_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\\n\",\n",
    "    \"    train_losses = []\\n\",\n",
    "    \"    val_losses = []\\n\",\n",
    "    \"    train_accuracies = []\\n\",\n",
    "    \"    val_accuracies = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    best_val_acc = 0.0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for epoch in range(num_epochs):\\n\",\n",
    "    \"        # Training phase\\n\",\n",
    "    \"        model.train()\\n\",\n",
    "    \"        running_loss = 0.0\\n\",\n",
    "    \"        correct = 0\\n\",\n",
    "    \"        total = 0\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/50')):\\n\",\n",
    "    \"            data, target = data.to(device), target.to(device)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            optimizer.zero_grad()\\n\",\n",
    "    \"            output = model(data)\\n\",\n",
    "    \"            loss = criterion(output, target)\\n\",\n",
    "    \"            loss.backward()\\n\",\n",
    "    \"            optimizer.step()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            running_loss += loss.item()\\n\",\n",
    "    \"            predicted = (output > 0.5).float()\\n\",\n",
    "    \"            total += target.size(0)\\n\",\n",
    "    \"            correct += (predicted == target).sum().item()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        train_loss = running_loss / len(train_loader)\\n\",\n",
    "    \"        train_acc = 100. * correct / total\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Validation phase\\n\",\n",
    "    \"        model.eval()\\n\",\n",
    "    \"        val_loss = 0.0\\n\",\n",
    "    \"        correct = 0\\n\",\n",
    "    \"        total = 0\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        with torch.no_grad():\\n\",\n",
    "    \"            for data, target in val_loader:\\n\",\n",
    "    \"                data, target = data.to(device), target.to(device)\\n\",\n",
    "    \"                output = model(data)\\n\",\n",
    "    \"                val_loss += criterion(output, target).item()\\n\",\n",
    "    \"                predicted = (output > 0.5).float()\\n\",\n",
    "    \"                total += target.size(0)\\n\",\n",
    "    \"                correct += (predicted == target).sum().item()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        val_loss /= len(val_loader)\\n\",\n",
    "    \"        val_acc = 100. * correct / total\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Store metrics\\n\",\n",
    "    \"        train_losses.append(train_loss)\\n\",\n",
    "    \"        val_losses.append(val_loss)\\n\",\n",
    "    \"        train_accuracies.append(train_acc)\\n\",\n",
    "    \"        val_accuracies.append(val_acc)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Learning rate scheduling\\n\",\n",
    "    \"        scheduler.step(val_loss)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Save best model\\n\",\n",
    "    \"        if val_acc > best_val_acc:\\n\",\n",
    "    \"            best_val_acc = val_acc\\n\",\n",
    "    \"            torch.save(model.state_dict(), os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_pytorch_model.pth'))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\\n\",\n",
    "    \"              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'train_loss': train_losses,\\n\",\n",
    "    \"        'val_loss': val_losses,\\n\",\n",
    "    \"        'train_acc': train_accuracies,\\n\",\n",
    "    \"        'val_acc': val_accuracies\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train PyTorch model\\n\",\n",
    "    \"print(\\\"Starting PyTorch model training...\\\")\\n\",\n",
    "    \"pytorch_history = train_pytorch_model(\\n\",\n",
    "    \"    pytorch_model, train_loader, val_loader, \\n\",\n",
    "    \"    criterion, optimizer, scheduler, CONFIG['EPOCHS']\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(\\\"PyTorch model training completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Model Evaluation and Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate TensorFlow models\\n\",\n",
    "    \"print(\\\"Evaluating TensorFlow models...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# CNN Model Evaluation\\n\",\n",
    "    \"cnn_test_loss, cnn_test_acc, cnn_test_precision, cnn_test_recall = cnn_model.evaluate(X_test, y_test, verbose=0)\\n\",\n",
    "    \"cnn_predictions = cnn_model.predict(X_test)\\n\",\n",
    "    \"cnn_pred_binary = (cnn_predictions > 0.5).astype(int).flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ResNet Model Evaluation\\n\",\n",
    "    \"resnet_test_loss, resnet_test_acc, resnet_test_precision, resnet_test_recall = resnet_model.evaluate(X_test, y_test, verbose=0)\\n\",\n",
    "    \"resnet_predictions = resnet_model.predict(X_test)\\n\",\n",
    "    \"resnet_pred_binary = (resnet_predictions > 0.5).astype(int).flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"CNN Model - Test Accuracy: {cnn_test_acc:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"ResNet Model - Test Accuracy: {resnet_test_acc:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate additional metrics\\n\",\n",
    "    \"from sklearn.metrics import f1_score, roc_auc_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"cnn_f1 = f1_score(y_test, cnn_pred_binary)\\n\",\n",
    "    \"cnn_auc = roc_auc_score(y_test, cnn_predictions)\\n\",\n",
    "    \"\\n\",\n",
    "    \"resnet_f1 = f1_score(y_test, resnet_pred_binary)\\n\",\n",
    "    \"resnet_auc = roc_auc_score(y_test, resnet_predictions)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"CNN Model - F1 Score: {cnn_f1:.4f}, AUC: {cnn_auc:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"ResNet Model - F1 Score: {resnet_f1:.4f}, AUC: {resnet_auc:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate PyTorch model\\n\",\n",
    "    \"def evaluate_pytorch_model(model, test_loader):\\n\",\n",
    "    \"    model.eval()\\n\",\n",
    "    \"    correct = 0\\n\",\n",
    "    \"    total = 0\\n\",\n",
    "    \"    all_predictions = []\\n\",\n",
    "    \"    all_targets = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for data, target in test_loader:\\n\",\n",
    "    \"            data, target = data.to(device), target.to(device)\\n\",\n",
    "    \"            output = model(data)\\n\",\n",
    "    \"            predicted = (output > 0.5).float()\\n\",\n",
    "    \"            total += target.size(0)\\n\",\n",
    "    \"            correct += (predicted == target).sum().item()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            all_predictions.extend(output.cpu().numpy())\\n\",\n",
    "    \"            all_targets.extend(target.cpu().numpy())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    accuracy = 100. * correct / total\\n\",\n",
    "    \"    return accuracy, np.array(all_predictions), np.array(all_targets).flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"pytorch_acc, pytorch_predictions, pytorch_targets = evaluate_pytorch_model(pytorch_model, test_loader)\\n\",\n",
    "    \"pytorch_pred_binary = (pytorch_predictions > 0.5).astype(int).flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"pytorch_f1 = f1_score(pytorch_targets, pytorch_pred_binary)\\n\",\n",
    "    \"pytorch_auc = roc_auc_score(pytorch_targets, pytorch_predictions)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"PyTorch Model - Test Accuracy: {pytorch_acc:.2f}%\\\")\\n\",\n",
    "    \"print(f\\\"PyTorch Model - F1 Score: {pytorch_f1:.4f}, AUC: {pytorch_auc:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comprehensive evaluation report\\n\",\n",
    "    \"def create_evaluation_report():\\n\",\n",
    "    \"    models_performance = {\\n\",\n",
    "    \"        'Model': ['CNN', 'ResNet', 'PyTorch ResNet'],\\n\",\n",
    "    \"        'Accuracy': [cnn_test_acc, resnet_test_acc, pytorch_acc/100],\\n\",\n",
    "    \"        'Precision': [cnn_test_precision, resnet_test_precision, None],\\n\",\n",
    "    \"        'Recall': [cnn_test_recall, resnet_test_recall, None],\\n\",\n",
    "    \"        'F1-Score': [cnn_f1, resnet_f1, pytorch_f1],\\n\",\n",
    "    \"        'AUC': [cnn_auc, resnet_auc, pytorch_auc]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_performance = pd.DataFrame(models_performance)\\n\",\n",
    "    \"    print(\\\"\\\\n=== Model Performance Comparison ===\\\")\\n\",\n",
    "    \"    print(df_performance.to_string(index=False))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df_performance\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_df = create_evaluation_report()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 12. Visualization of Training History\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history\\n\",\n",
    "    \"def plot_training_history(histories, model_names):\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot training & validation accuracy\\n\",\n",
    "    \"    axes[0, 0].set_title('Model Accuracy')\\n\",\n",
    "    \"    for i, (history, name) in enumerate(zip(histories, model_names)):\\n\",\n",
    "    \"        if 'accuracy' in history:\\n\",\n",
    "    \"            axes[0, 0].plot(history['accuracy'], label=f'{name} Train')\\n\",\n",
    "    \"            axes[0, 0].plot(history['val_accuracy'], label=f'{name} Val')\\n\",\n",
    "    \"        elif 'train_acc' in history:\\n\",\n",
    "    \"            axes[0, 0].plot([acc/100 for acc in history['train_acc']], label=f'{name} Train')\\n\",\n",
    "    \"            axes[0, 0].plot([acc/100 for acc in history['val_acc']], label=f'{name} Val')\\n\",\n",
    "    \"    axes[0, 0].set_ylabel('Accuracy')\\n\",\n",
    "    \"    axes[0, 0].set_xlabel('Epoch')\\n\",\n",
    "    \"    axes[0, 0].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot training & validation loss\\n\",\n",
    "    \"    axes[0, 1].set_title('Model Loss')\\n\",\n",
    "    \"    for i, (history, name) in enumerate(zip(histories, model_names)):\\n\",\n",
    "    \"        if 'loss' in history:\\n\",\n",
    "    \"            axes[0, 1].plot(history['loss'], label=f'{name} Train')\\n\",\n",
    "    \"            axes[0, 1].plot(history['val_loss'], label=f'{name} Val')\\n\",\n",
    "    \"        elif 'train_loss' in history:\\n\",\n",
    "    \"            axes[0, 1].plot(history['train_loss'], label=f'{name} Train')\\n\",\n",
    "    \"            axes[0, 1].plot(history['val_loss'], label=f'{name} Val')\\n\",\n",
    "    \"    axes[0, 1].set_ylabel('Loss')\\n\",\n",
    "    \"    axes[0, 1].set_xlabel('Epoch')\\n\",\n",
    "    \"    axes[0, 1].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot ROC curves\\n\",\n",
    "    \"    axes[1, 0].set_title('ROC Curves')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # CNN ROC\\n\",\n",
    "    \"    fpr_cnn, tpr_cnn, _ = roc_curve(y_test, cnn_predictions)\\n\",\n",
    "    \"    axes[1, 0].plot(fpr_cnn, tpr_cnn, label=f'CNN (AUC = {cnn_auc:.3f})')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # ResNet ROC\\n\",\n",
    "    \"    fpr_resnet, tpr_resnet, _ = roc_curve(y_test, resnet_predictions)\\n\",\n",
    "    \"    axes[1, 0].plot(fpr_resnet, tpr_resnet, label=f'ResNet (AUC = {resnet_auc:.3f})')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # PyTorch ROC\\n\",\n",
    "    \"    fpr_pytorch, tpr_pytorch, _ = roc_curve(pytorch_targets, pytorch_predictions)\\n\",\n",
    "    \"    axes[1, 0].plot(fpr_pytorch, tpr_pytorch, label=f'PyTorch (AUC = {pytorch_auc:.3f})')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Random')\\n\",\n",
    "    \"    axes[1, 0].set_xlabel('False Positive Rate')\\n\",\n",
    "    \"    axes[1, 0].set_ylabel('True Positive Rate')\\n\",\n",
    "    \"    axes[1, 0].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot confusion matrices\\n\",\n",
    "    \"    axes[1, 1].set_title('Model Performance Comparison')\\n\",\n",
    "    \"    x = np.arange(len(model_names))\\n\",\n",
    "    \"    accuracies = [cnn_test_acc, resnet_test_acc, pytorch_acc/100]\\n\",\n",
    "    \"    f1_scores = [cnn_f1, resnet_f1, pytorch_f1]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    width = 0.35\\n\",\n",
    "    \"    axes[1, 1].bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8)\\n\",\n",
    "    \"    axes[1, 1].bar(x + width/2, f1_scores, width, label='F1-Score', alpha=0.8)\\n\",\n",
    "    \"    axes[1, 1].set_xlabel('Models')\\n\",\n",
    "    \"    axes[1, 1].set_ylabel('Score')\\n\",\n",
    "    \"    axes[1, 1].set_xticks(x)\\n\",\n",
    "    \"    axes[1, 1].set_xticklabels(model_names)\\n\",\n",
    "    \"    axes[1, 1].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot training histories\\n\",\n",
    "    \"histories = [cnn_history.history, resnet_history.history, pytorch_history]\\n\",\n",
    "    \"model_names = ['CNN', 'ResNet', 'PyTorch']\\n\",\n",
    "    \"plot_training_history(histories, model_names)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 13. Confusion Matrix Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot confusion matrices for all models\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"models_data = [\\n\",\n",
    "    \"    (y_test, cnn_pred_binary, 'CNN Model'),\\n\",\n",
    "    \"    (y_test, resnet_pred_binary, 'ResNet Model'),\\n\",\n",
    "    \"    (pytorch_targets, pytorch_pred_binary, 'PyTorch Model')\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, (true_labels, predictions, title) in enumerate(models_data):\\n\",\n",
    "    \"    cm = confusion_matrix(true_labels, predictions)\\n\",\n",
    "    \"    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\\n\",\n",
    "    \"    axes[i].set_title(title)\\n\",\n",
    "    \"    axes[i].set_xlabel('Predicted')\\n\",\n",
    "    \"    axes[i].set_ylabel('Actual')\\n\",\n",
    "    \"    axes[i].set_xticklabels(['Fake', 'Real'])\\n\",\n",
    "    \"    axes[i].set_yticklabels(['Fake', 'Real'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 14. Model Interpretability - Feature Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Grad-CAM implementation for model interpretability\\n\",\n",
    "    \"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\\n\",\n",
    "    \"    # First, we create a model that maps the input image to the activations\\n\",\n",
    "    \"    # of the last conv layer as well as the output predictions\\n\",\n",
    "    \"    grad_model = tf.keras.models.Model(\\n\",\n",
    "    \"        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Then, we compute the gradient of the top predicted class for our input image\\n\",\n",
    "    \"    # with respect to the activations of the last conv layer\\n\",\n",
    "    \"    with tf.GradientTape() as tape:\\n\",\n",
    "    \"        last_conv_layer_output, preds = grad_model(img_array)\\n\",\n",
    "    \"        if pred_index is None:\\n\",\n",
    "    \"            pred_index = tf.argmax(preds[0])\\n\",\n",
    "    \"        class_channel = preds[:, pred_index]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # This is the gradient of the output neuron (top predicted or chosen)\\n\",\n",
    "    \"    # with regard to the output feature map of the last conv layer\\n\",\n",
    "    \"    grads = tape.gradient(class_channel, last_conv_layer_output)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # This is a vector where each entry is the mean intensity of the gradient\\n\",\n",
    "    \"    # over a specific feature map channel\\n\",\n",
    "    \"    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # We multiply each channel in the feature map array\\n\",\n",
    "    \"    # by \\\"how important this channel is\\\" with regard to the top predicted class\\n\",\n",
    "    \"    last_conv_layer_output = last_conv_layer_output[0]\\n\",\n",
    "    \"    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\\n\",\n",
    "    \"    heatmap = tf.squeeze(heatmap)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # For visualization purpose, we will also normalize the heatmap between 0 & 1\\n\",\n",
    "    \"    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\\n\",\n",
    "    \"    return heatmap.numpy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize Grad-CAM for a few test images\\n\",\n",
    "    \"def visualize_gradcam(model, images, true_labels, predictions, num_images=4):\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, num_images, figsize=(16, 8))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(num_images):\\n\",\n",
    "    \"        img = images[i:i+1]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get the last convolutional layer name\\n\",\n",
    "    \"        last_conv_layer_name = None\\n\",\n",
    "    \"        for layer in reversed(model.layers):\\n\",\n",
    "    \"            if len(layer.output_shape) == 4:\\n\",\n",
    "    \"                last_conv_layer_name = layer.name\\n\",\n",
    "    \"                break\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if last_conv_layer_name:\\n\",\n",
    "    \"            # Generate heatmap\\n\",\n",
    "    \"            heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Display original image\\n\",\n",
    "    \"            axes[0, i].imshow(images[i])\\n\",\n",
    "    \"            axes[0, i].set_title(f'True: {\\\"Real\\\" if true_labels[i] else \\\"Fake\\\"}\\\\n'\\n\",\n",
    "    \"                               f'Pred: {\\\"Real\\\" if predictions[i] > 0.5 else \\\"Fake\\\"} ({predictions[i]:.3f})')\\n\",\n",
    "    \"            axes[0, i].axis('off')\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Display heatmap\\n\",\n",
    "    \"            axes[1, i].imshow(images[i])\\n\",\n",
    "    \"            axes[1, i].imshow(heatmap, alpha=0.6, cmap='jet')\\n\",\n",
    "    \"            axes[1, i].set_title('Grad-CAM')\\n\",\n",
    "    \"            axes[1, i].axis('off')\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            axes[0, i].text(0.5, 0.5, 'No conv layer found', ha='center', va='center')\\n\",\n",
    "    \"            axes[1, i].text(0.5, 0\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"# Continuation of the fake image detection notebook\n",
    "\n",
    "# Complete the Grad-CAM visualization function\n",
    "def visualize_gradcam(model, images, true_labels, predictions, num_images=4):\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(16, 8))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        img = images[i:i+1]\n",
    "        \n",
    "        # Get the last convolutional layer name\n",
    "        last_conv_layer_name = None\n",
    "        for layer in reversed(model.layers):\n",
    "            if len(layer.output_shape) == 4:\n",
    "                last_conv_layer_name = layer.name\n",
    "                break\n",
    "        \n",
    "        if last_conv_layer_name:\n",
    "            # Generate heatmap\n",
    "            heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name)\n",
    "            \n",
    "            # Display original image\n",
    "            axes[0, i].imshow(images[i])\n",
    "            axes[0, i].set_title(f'True: {\"Real\" if true_labels[i] else \"Fake\"}\\n'\n",
    "                               f'Pred: {\"Real\" if predictions[i] > 0.5 else \"Fake\"} ({predictions[i]:.3f})')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Display heatmap\n",
    "            axes[1, i].imshow(images[i])\n",
    "            axes[1, i].imshow(heatmap, alpha=0.6, cmap='jet')\n",
    "            axes[1, i].set_title('Grad-CAM')\n",
    "            axes[1, i].axis('off')\n",
    "        else:\n",
    "            axes[0, i].text(0.5, 0.5, 'No conv layer found', ha='center', va='center')\n",
    "            axes[1, i].text(0.5, 0.5, 'No conv layer found', ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply Grad-CAM to ResNet model\n",
    "print(\"Generating Grad-CAM visualizations...\")\n",
    "try:\n",
    "    # Select a few test images for visualization\n",
    "    sample_indices = np.random.choice(len(X_test), 4, replace=False)\n",
    "    sample_images = X_test[sample_indices]\n",
    "    sample_labels = y_test[sample_indices]\n",
    "    sample_predictions = resnet_predictions[sample_indices].flatten()\n",
    "    \n",
    "    visualize_gradcam(resnet_model, sample_images, sample_labels, sample_predictions)\n",
    "except Exception as e:\n",
    "    print(f\"Grad-CAM visualization failed: {e}\")\n",
    "    print(\"Skipping Grad-CAM visualization...\")\n",
    "\n",
    "# 15. Error Analysis\n",
    "print(\"\\n=== Error Analysis ===\")\n",
    "\n",
    "# Find misclassified samples\n",
    "def analyze_errors(true_labels, predictions, images, model_name):\n",
    "    pred_binary = (predictions > 0.5).astype(int).flatten()\n",
    "    misclassified = np.where(true_labels != pred_binary)[0]\n",
    "    \n",
    "    print(f\"\\n{model_name} - Misclassified samples: {len(misclassified)}\")\n",
    "    \n",
    "    if len(misclassified) > 0:\n",
    "        # False positives (predicted real, actually fake)\n",
    "        false_positives = misclassified[(true_labels[misclassified] == 0) & (pred_binary[misclassified] == 1)]\n",
    "        # False negatives (predicted fake, actually real)\n",
    "        false_negatives = misclassified[(true_labels[misclassified] == 1) & (pred_binary[misclassified] == 0)]\n",
    "        \n",
    "        print(f\"False Positives: {len(false_positives)}\")\n",
    "        print(f\"False Negatives: {len(false_negatives)}\")\n",
    "        \n",
    "        # Visualize some misclassified samples\n",
    "        if len(misclassified) >= 4:\n",
    "            sample_errors = np.random.choice(misclassified, min(4, len(misclassified)), replace=False)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, len(sample_errors), figsize=(16, 4))\n",
    "            if len(sample_errors) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, idx in enumerate(sample_errors):\n",
    "                axes[i].imshow(images[idx])\n",
    "                axes[i].set_title(f'True: {\"Real\" if true_labels[idx] else \"Fake\"}\\n'\n",
    "                                f'Pred: {\"Real\" if pred_binary[idx] else \"Fake\"}\\n'\n",
    "                                f'Confidence: {predictions[idx]:.3f}')\n",
    "                axes[i].axis('off')\n",
    "            \n",
    "            plt.suptitle(f'{model_name} - Misclassified Samples')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return misclassified\n",
    "\n",
    "# Analyze errors for each model\n",
    "cnn_errors = analyze_errors(y_test, cnn_predictions.flatten(), X_test, \"CNN\")\n",
    "resnet_errors = analyze_errors(y_test, resnet_predictions.flatten(), X_test, \"ResNet\")\n",
    "pytorch_errors = analyze_errors(pytorch_targets, pytorch_predictions.flatten(), X_test, \"PyTorch\")\n",
    "\n",
    "# 16. Model Ensemble\n",
    "print(\"\\n=== Creating Model Ensemble ===\")\n",
    "\n",
    "# Create ensemble predictions\n",
    "ensemble_predictions = (cnn_predictions.flatten() + resnet_predictions.flatten() + pytorch_predictions.flatten()) / 3\n",
    "ensemble_pred_binary = (ensemble_predictions > 0.5).astype(int)\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_acc = np.mean(ensemble_pred_binary == y_test)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred_binary)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Performance:\")\n",
    "print(f\"Accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"F1-Score: {ensemble_f1:.4f}\")\n",
    "print(f\"AUC: {ensemble_auc:.4f}\")\n",
    "\n",
    "# Update performance comparison\n",
    "ensemble_row = {\n",
    "    'Model': 'Ensemble',\n",
    "    'Accuracy': ensemble_acc,\n",
    "    'Precision': None,\n",
    "    'Recall': None,\n",
    "    'F1-Score': ensemble_f1,\n",
    "    'AUC': ensemble_auc\n",
    "}\n",
    "\n",
    "performance_df = pd.concat([performance_df, pd.DataFrame([ensemble_row])], ignore_index=True)\n",
    "print(\"\\n=== Updated Model Performance Comparison ===\")\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# 17. Feature Importance Analysis\n",
    "print(\"\\n=== Feature Importance Analysis ===\")\n",
    "\n",
    "def analyze_feature_importance(model, X_sample, layer_name=None):\n",
    "    \"\"\"\n",
    "    Analyze which parts of images are most important for classification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get intermediate layer outputs\n",
    "        if layer_name is None:\n",
    "            # Find last convolutional layer\n",
    "            for layer in reversed(model.layers):\n",
    "                if 'conv' in layer.name.lower():\n",
    "                    layer_name = layer.name\n",
    "                    break\n",
    "        \n",
    "        if layer_name:\n",
    "            intermediate_model = tf.keras.Model(\n",
    "                inputs=model.input,\n",
    "                outputs=model.get_layer(layer_name).output\n",
    "            )\n",
    "            \n",
    "            # Get feature maps\n",
    "            feature_maps = intermediate_model.predict(X_sample[:4])\n",
    "            \n",
    "            # Visualize feature maps\n",
    "            fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "            for i in range(4):\n",
    "                for j in range(4):\n",
    "                    if j < feature_maps.shape[-1]:\n",
    "                        axes[i, j].imshow(feature_maps[i, :, :, j], cmap='viridis')\n",
    "                        axes[i, j].set_title(f'Sample {i+1}, Filter {j+1}')\n",
    "                        axes[i, j].axis('off')\n",
    "            \n",
    "            plt.suptitle(f'Feature Maps from {layer_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Feature importance analysis failed: {e}\")\n",
    "\n",
    "# Analyze feature importance for ResNet model\n",
    "analyze_feature_importance(resnet_model, X_test)\n",
    "\n",
    "# 18. Model Comparison Summary\n",
    "print(\"\\n=== Final Model Comparison Summary ===\")\n",
    "\n",
    "# Create a comprehensive comparison\n",
    "comparison_data = {\n",
    "    'Metric': ['Accuracy', 'F1-Score', 'AUC-ROC', 'Training Time (relative)'],\n",
    "    'CNN': [f\"{cnn_test_acc:.4f}\", f\"{cnn_f1:.4f}\", f\"{cnn_auc:.4f}\", \"Fast\"],\n",
    "    'ResNet': [f\"{resnet_test_acc:.4f}\", f\"{resnet_f1:.4f}\", f\"{resnet_auc:.4f}\", \"Medium\"],\n",
    "    'PyTorch': [f\"{pytorch_acc/100:.4f}\", f\"{pytorch_f1:.4f}\", f\"{pytorch_auc:.4f}\", \"Medium\"],\n",
    "    'Ensemble': [f\"{ensemble_acc:.4f}\", f\"{ensemble_f1:.4f}\", f\"{ensemble_auc:.4f}\", \"Slow\"]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = performance_df['AUC'].idxmax()\n",
    "best_model = performance_df.loc[best_model_idx, 'Model']\n",
    "best_auc = performance_df.loc[best_model_idx, 'AUC']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model} with AUC: {best_auc:.4f}\")\n",
    "\n",
    "# 19. Save Final Models and Results\n",
    "print(\"\\n=== Saving Models and Results ===\")\n",
    "\n",
    "# Save model architectures and weights\n",
    "try:\n",
    "    # Save TensorFlow models\n",
    "    cnn_model.save(os.path.join(CONFIG['MODEL_SAVE_DIR'], 'final_cnn_model.h5'))\n",
    "    resnet_model.save(os.path.join(CONFIG['MODEL_SAVE_DIR'], 'final_resnet_model.h5'))\n",
    "    \n",
    "    # Save PyTorch model\n",
    "    torch.save({\n",
    "        'model_state_dict': pytorch_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'config': CONFIG\n",
    "    }, os.path.join(CONFIG['MODEL_SAVE_DIR'], 'final_pytorch_model.pth'))\n",
    "    \n",
    "    print(\"Models saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {e}\")\n",
    "\n",
    "# Save performance results\n",
    "try:\n",
    "    performance_df.to_csv(os.path.join(CONFIG['MODEL_SAVE_DIR'], 'model_performance.csv'), index=False)\n",
    "    \n",
    "    # Save detailed results\n",
    "    results = {\n",
    "        'cnn_predictions': cnn_predictions.flatten().tolist(),\n",
    "        'resnet_predictions': resnet_predictions.flatten().tolist(),\n",
    "        'pytorch_predictions': pytorch_predictions.flatten().tolist(),\n",
    "        'ensemble_predictions': ensemble_predictions.tolist(),\n",
    "        'true_labels': y_test.tolist(),\n",
    "        'config': CONFIG\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(CONFIG['MODEL_SAVE_DIR'], 'detailed_results.json'), 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"Results saved successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving results: {e}\")\n",
    "\n",
    "# 20. Model Deployment Preparation\n",
    "print(\"\\n=== Model Deployment Preparation ===\")\n",
    "\n",
    "def create_inference_function(model, img_size):\n",
    "    \"\"\"\n",
    "    Create a function for model inference on new images\n",
    "    \"\"\"\n",
    "    def predict_image(image_path):\n",
    "        try:\n",
    "            # Load and preprocess image\n",
    "            img = load_and_preprocess_image(image_path, img_size)\n",
    "            if img is None:\n",
    "                return None, \"Error loading image\"\n",
    "            \n",
    "            # Make prediction\n",
    "            img_batch = np.expand_dims(img, axis=0)\n",
    "            prediction = model.predict(img_batch)[0][0]\n",
    "            \n",
    "            # Determine result\n",
    "            is_real = prediction > 0.5\n",
    "            confidence = prediction if is_real else 1 - prediction\n",
    "            \n",
    "            result = {\n",
    "                'prediction': 'Real' if is_real else 'Fake',\n",
    "                'confidence': float(confidence),\n",
    "                'raw_score': float(prediction)\n",
    "            }\n",
    "            \n",
    "            return result, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, str(e)\n",
    "    \n",
    "    return predict_image\n",
    "\n",
    "# Create inference functions for best model\n",
    "if best_model == 'ResNet':\n",
    "    best_tf_model = resnet_model\n",
    "elif best_model == 'CNN':\n",
    "    best_tf_model = cnn_model\n",
    "else:\n",
    "    best_tf_model = resnet_model  # Default to ResNet\n",
    "\n",
    "inference_fn = create_inference_function(best_tf_model, CONFIG['IMG_SIZE'])\n",
    "\n",
    "print(f\"Inference function created for {best_model} model\")\n",
    "print(\"Usage: result, error = inference_fn('path/to/image.jpg')\")\n",
    "\n",
    "# 21. Generate Classification Report\n",
    "print(\"\\n=== Detailed Classification Reports ===\")\n",
    "\n",
    "# Generate classification reports for all models\n",
    "models_info = [\n",
    "    ('CNN', y_test, cnn_pred_binary),\n",
    "    ('ResNet', y_test, resnet_pred_binary),\n",
    "    ('PyTorch', pytorch_targets, pytorch_pred_binary),\n",
    "    ('Ensemble', y_test, ensemble_pred_binary)\n",
    "]\n",
    "\n",
    "for model_name, true_labels, predictions in models_info:\n",
    "    print(f\"\\n{model_name} Model Classification Report:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(classification_report(true_labels, predictions, \n",
    "                              target_names=['Fake', 'Real'], \n",
    "                              digits=4))\n",
    "\n",
    "# 22. Final Recommendations and Next Steps\n",
    "print(\"\\n=== Recommendations and Next Steps ===\")\n",
    "print(\"\"\"\n",
    "RECOMMENDATIONS:\n",
    "1. Best Model: {} with AUC: {:.4f}\n",
    "2. Ensemble approach shows promising results\n",
    "3. Consider data augmentation techniques for better generalization\n",
    "4. Implement additional evaluation metrics (precision-recall curves)\n",
    "5. Test on different types of fake images (deepfakes, GAN-generated, etc.)\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Deploy the best model to production\n",
    "2. Implement real-time inference pipeline\n",
    "3. Create model monitoring and retraining pipeline\n",
    "4. Collect more diverse training data\n",
    "5. Experiment with newer architectures (Vision Transformers, EfficientNet)\n",
    "6. Implement adversarial training for robustness\n",
    "\n",
    "MODEL FILES SAVED:\n",
    "- final_cnn_model.h5\n",
    "- final_resnet_model.h5\n",
    "- final_pytorch_model.pth\n",
    "- model_performance.csv\n",
    "- detailed_results.json\n",
    "\"\"\".format(best_model, best_auc))\n",
    "\n",
    "print(\"\\n=== Training Pipeline Completed Successfully ===\")\n",
    "print(f\"Total models trained: 4 (CNN, ResNet, PyTorch ResNet, Ensemble)\")\n",
    "print(f\"Best model: {best_model}\")import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "from utils.data_preprocessing import load_and_preprocess_image\n",
    "from utils.visualization import plot_sample_images, plot_roc_curve, plot_confusion_matrix\n",
    "from utils.metrics import plot_training_history_tf, plot_training_history_torch # Assuming these are in utils.metrics\n",
    "from models.cnn_model import build_cnn_model # Assuming these are defined in models\n",
    "from models.resnet_model import build_resnet_model # Assuming these are defined in models\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# GPU Configuration\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Configuration and Hyperparameters\n",
    "\n",
    "```python\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'DATA_DIR': '../data',\n",
    "    'REAL_DIR': '../data/real',\n",
    "    'FAKE_DIR': '../data/fake',\n",
    "    'TEST_DIR': '../data/test',\n",
    "    'MODEL_SAVE_DIR': '../models/saved_models',\n",
    "    \n",
    "    # Image parameters\n",
    "    'IMG_SIZE': (224, 224),\n",
    "    'BATCH_SIZE': 32,\n",
    "    'CHANNELS': 3,\n",
    "    \n",
    "    # Training parameters\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'VALIDATION_SPLIT': 0.2,\n",
    "    'TEST_SPLIT': 0.1,\n",
    "    \n",
    "    # Model parameters\n",
    "    'DROPOUT_RATE': 0.5,\n",
    "    'L2_REGULARIZATION': 0.01,\n",
    "    \n",
    "    # Callbacks\n",
    "    'EARLY_STOPPING_PATIENCE': 10,\n",
    "    'REDUCE_LR_PATIENCE': 5,\n",
    "    'REDUCE_LR_FACTOR': 0.5\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(CONFIG['MODEL_SAVE_DIR'], exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Image size: {CONFIG['IMG_SIZE']}\")\n",
    "print(f\"Batch size: {CONFIG['BATCH_SIZE']}\")\n",
    "print(f\"Epochs: {CONFIG['EPOCHS']}\")\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data Loading and Preprocessing\n",
    "\n",
    "```python\n",
    "# Load and preprocess data\n",
    "def load_dataset(real_dir, fake_dir, img_size):\n",
    "    \"\"\"\n",
    "    Load images from real and fake directories\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    \n",
    "    # Load real images (label = 1)\n",
    "    real_files = [f for f in os.listdir(real_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(real_files)} real images\")\n",
    "    \n",
    "    for filename in tqdm(real_files, desc=\"Loading real images\"):\n",
    "        filepath = os.path.join(real_dir, filename)\n",
    "        img = load_and_preprocess_image(filepath, img_size)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(1)  # Real = 1\n",
    "            filepaths.append(filepath)\n",
    "    \n",
    "    # Load fake images (label = 0)\n",
    "    fake_files = [f for f in os.listdir(fake_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"Found {len(fake_files)} fake images\")\n",
    "    \n",
    "    for filename in tqdm(fake_files, desc=\"Loading fake images\"):\n",
    "        filepath = os.path.join(fake_dir, filename)\n",
    "        img = load_and_preprocess_image(filepath, img_size)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(0)  # Fake = 0\n",
    "            filepaths.append(filepath)\n",
    "    \n",
    "    return np.array(images), np.array(labels), filepaths\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "X, y, filepaths = load_dataset(CONFIG['REAL_DIR'], CONFIG['FAKE_DIR'], CONFIG['IMG_SIZE'])\n",
    "\n",
    "print(f\"Total images loaded: {len(X)}\")\n",
    "print(f\"Real images: {np.sum(y)}\")\n",
    "print(f\"Fake images: {len(y) - np.sum(y)}\")\n",
    "print(f\"Image shape: {X.shape}\")\n",
    "print(f\"Label distribution: {np.bincount(y)}\")\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Data Exploration and Visualization\n",
    "\n",
    "```python\n",
    "# Visualize sample images\n",
    "plot_sample_images(X, y, num_samples=8)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "labels_text = ['Fake', 'Real']\n",
    "counts = np.bincount(y)\n",
    "plt.bar(labels_text, counts, color=['red', 'green'], alpha=0.7)\n",
    "plt.title('Class Distribution')\n",
    "plt.ylabel('Number of Images')\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 10, str(count), ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display basic statistics\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Image dimensions: {X.shape[1:]}\")\n",
    "print(f\"Pixel value range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "print(f\"Mean pixel value: {X.mean():.3f}\")\n",
    "print(f\"Std pixel value: {X.std():.3f}\")\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Data Augmentation Setup\n",
    "\n",
    "```python\n",
    "# TensorFlow Data Augmentation\n",
    "tf_train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=CONFIG['VALIDATION_SPLIT']\n",
    ")\n",
    "\n",
    "tf_val_datagen = ImageDataGenerator(\n",
    "    validation_split=CONFIG['VALIDATION_SPLIT']\n",
    ")\n",
    "\n",
    "# PyTorch Data Augmentation using Albumentations\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CONFIG['IMG_SIZE'][0], CONFIG['IMG_SIZE'][1]),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CONFIG['IMG_SIZE'][0], CONFIG['IMG_SIZE'][1]),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(\"Data augmentation pipelines created successfully!\")\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Data Splitting\n",
    "\n",
    "```python\n",
    "# Split the data\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=CONFIG['TEST_SPLIT'], \n",
    "    stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=CONFIG['VALIDATION_SPLIT']/(1-CONFIG['TEST_SPLIT']), \n",
    "    stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"Real: {np.sum(y_train)}, Fake: {len(y_train) - np.sum(y_train)}\")\n",
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(f\"Real: {np.sum(y_val)}, Fake: {len(y_val) - np.sum(y_val)}\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(f\"Real: {np.sum(y_test)}, Fake: {len(y_test) - np.sum(y_test)}\")\n",
    "\n",
    "---\n",
    "\n",
    "## 7. TensorFlow/Keras Model Training\n",
    "\n",
    "```python\n",
    "# Build CNN Model\n",
    "def build_cnn_model(input_shape, num_classes=1):\n",
    "    model = models.Sequential([\n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Fourth Convolutional Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(CONFIG['DROPOUT_RATE']),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(CONFIG['DROPOUT_RATE']),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (*CONFIG['IMG_SIZE'], CONFIG['CHANNELS'])\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "```python\n",
    "# Setup callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=CONFIG['REDUCE_LR_FACTOR'],\n",
    "        patience=CONFIG['REDUCE_LR_PATIENCE'],\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_cnn_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured successfully!\")\n",
    "\n",
    "```python\n",
    "# Train the CNN model\n",
    "print(\"Starting CNN model training...\")\n",
    "\n",
    "cnn_history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"CNN model training completed!\")\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Transfer Learning with ResNet\n",
    "\n",
    "```python\n",
    "# Build ResNet-based model\n",
    "def build_resnet_model(input_shape, num_classes=1):\n",
    "    # Load pre-trained ResNet50\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom layers\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Build ResNet model\n",
    "resnet_model, base_model = build_resnet_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "resnet_model.summary()\n",
    "\n",
    "```python\n",
    "# Setup callbacks for ResNet\n",
    "resnet_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=CONFIG['EARLY_STOPPING_PATIENCE'],\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=CONFIG['REDUCE_LR_FACTOR'],\n",
    "        patience=CONFIG['REDUCE_LR_PATIENCE'],\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_resnet_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train ResNet model\n",
    "print(\"Starting ResNet model training...\")\n",
    "\n",
    "resnet_history = resnet_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=resnet_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ResNet model training completed!\")\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Fine-tuning ResNet\n",
    "\n",
    "```python\n",
    "# Fine-tune the ResNet model\n",
    "print(\"Starting fine-tuning of ResNet model...\")\n",
    "\n",
    "# Unfreeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=CONFIG['LEARNING_RATE']/10),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Fine-tune callbacks\n",
    "finetune_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_resnet_finetuned.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "finetune_epochs = 10\n",
    "total_epochs = len(resnet_history.history['loss']) + finetune_epochs\n",
    "\n",
    "resnet_finetune_history = resnet_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=CONFIG['BATCH_SIZE'],\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=len(resnet_history.history['loss']),\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=finetune_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed!\")\n",
    "\n",
    "---\n",
    "\n",
    "## 10. PyTorch Model Training\n",
    "\n",
    "```python\n",
    "# PyTorch Dataset Class\n",
    "class FakeImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            # Convert to uint8 for albumentations\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        else:\n",
    "            image = torch.FloatTensor(image).permute(2, 0, 1)\n",
    "        \n",
    "        return image, torch.FloatTensor([label])\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = FakeImageDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = FakeImageDataset(X_val, y_val, transform=val_transform)\n",
    "test_dataset = FakeImageDataset(X_test, y_test, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "print(f\"PyTorch datasets created:\")\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "```python\n",
    "# PyTorch ResNet Model\n",
    "class PyTorchResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(PyTorchResNetModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze last few layers\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Replace the classifier\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Initialize PyTorch model\n",
    "pytorch_model = PyTorchResNetModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(pytorch_model.parameters(), lr=CONFIG['LEARNING_RATE'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "print(\"PyTorch model initialized!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in pytorch_model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "```python\n",
    "# PyTorch training function\n",
    "def train_pytorch_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (output > 0.5).float()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                predicted = (output > 0.5).float()\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(CONFIG['MODEL_SAVE_DIR'], 'best_pytorch_model.pth'))\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accuracies,\n",
    "        'val_acc': val_accuracies\n",
    "    }\n",
    "\n",
    "# Train PyTorch model\n",
    "print(\"Starting PyTorch model training...\")\n",
    "pytorch_history = train_pytorch_model(\n",
    "    pytorch_model, train_loader, val_loader, \n",
    "    criterion, optimizer, scheduler, CONFIG['EPOCHS']\n",
    ")\n",
    "print(\"PyTorch model training completed!\")\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Model Evaluation and Comparison\n",
    "\n",
    "```python\n",
    "# Evaluate TensorFlow models\n",
    "print(\"Evaluating TensorFlow models...\")\n",
    "\n",
    "# CNN Model Evaluation\n",
    "cnn_test_loss, cnn_test_acc, cnn_test_precision, cnn_test_recall = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "cnn_predictions = cnn_model.predict(X_test)\n",
    "cnn_pred_binary = (cnn_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# ResNet Model Evaluation\n",
    "resnet_test_loss, resnet_test_acc, resnet_test_precision, resnet_test_recall = resnet_model.evaluate(X_test, y_test, verbose=0)\n",
    "resnet_predictions = resnet_model.predict(X_test)\n",
    "resnet_pred_binary = (resnet_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"CNN Model - Test Accuracy: {cnn_test_acc:.4f}\")\n",
    "print(f\"ResNet Model - Test Accuracy: {resnet_test_acc:.4f}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "cnn_f1 = f1_score(y_test, cnn_pred_binary)\n",
    "cnn_auc = roc_auc_score(y_test, cnn_predictions)\n",
    "\n",
    "resnet_f1 = f1_score(y_test, resnet_pred_binary)\n",
    "resnet_auc = roc_auc_score(y_test, resnet_predictions)\n",
    "\n",
    "print(f\"CNN Model - F1 Score: {cnn_f1:.4f}, AUC: {cnn_auc:.4f}\")\n",
    "print(f\"ResNet Model - F1 Score: {resnet_f1:.4f}, AUC: {resnet_auc:.4f}\")\n",
    "\n",
    "```python\n",
    "# Evaluate PyTorch model\n",
    "def evaluate_pytorch_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            predicted = (output > 0.5).float()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            all_predictions.extend(output.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    return accuracy, np.array(all_predictions), np.array(all_targets).flatten()\n",
    "\n",
    "pytorch_acc, pytorch_predictions, pytorch_targets = evaluate_pytorch_model(pytorch_model, test_loader)\n",
    "pytorch_pred_binary = (pytorch_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "pytorch_f1 = f1_score(pytorch_targets, pytorch_pred_binary)\n",
    "pytorch_auc = roc_auc_score(pytorch_targets, pytorch_predictions)\n",
    "\n",
    "print(f\"PyTorch Model - Test Accuracy: {pytorch_acc:.2f}%\")\n",
    "print(f\"PyTorch Model - F1 Score: {pytorch_f1:.4f}, AUC: {pytorch_auc:.4f}\")\n",
    "\n",
    "```python\n",
    "# Create comprehensive evaluation report\n",
    "def create_evaluation_report():\n",
    "    models_performance = {\n",
    "        'Model': ['CNN', 'ResNet', 'PyTorch ResNet'],\n",
    "        'Accuracy': [cnn_test_acc, resnet_test_acc, pytorch_acc/100],\n",
    "        'Precision': [cnn_test_precision, resnet_test_precision, None], # Precision/Recall need to be calculated for PyTorch separately if needed.\n",
    "        'Recall': [cnn_test_recall, resnet_test_recall, None], # Placeholder as they weren't explicitly calculated in the PyTorch eval function\n",
    "        'F1-Score': [cnn_f1, resnet_f1, pytorch_f1],\n",
    "        'AUC': [cnn_auc, resnet_auc, pytorch_auc]\n",
    "    }\n",
    "    \n",
    "    df_performance = pd.DataFrame(models_performance)\n",
    "    print(\"\\n=== Model Performance Comparison ===\")\n",
    "    print(df_performance.to_string(index=False))\n",
    "    \n",
    "    return df_performance\n",
    "\n",
    "performance_df = create_evaluation_report()\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Visualization of Training History\n",
    "\n",
    "```python\n",
    "# Plot training history\n",
    "def plot_training_history(histories, model_names):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "        if 'accuracy' in history:\n",
    "            axes[0, 0].plot(history['accuracy'], label=f'{name} Train')\n",
    "            axes[0, 0].plot(history['val_accuracy'], label=f'{name} Val')\n",
    "        elif 'train_acc' in history:\n",
    "            axes[0, 0].plot([acc/100 for acc in history['train_acc']], label=f'{name} Train')\n",
    "            axes[0, 0].plot([acc/100 for acc in history['val_acc']], label=f'{name} Val')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    for i, (history, name) in enumerate(zip(histories, model_names)):\n",
    "        if 'loss' in history:\n",
    "            axes[0, 1].plot(history['loss'], label=f'{name} Train')\n",
    "            axes[0, 1].plot(history['val_loss'], label=f'{name} Val')\n",
    "        elif 'train_loss' in history:\n",
    "            axes[0, 1].plot(history['train_loss'], label=f'{name} Train')\n",
    "            axes[0, 1].plot(history['val_loss'], label=f'{name} Val')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # Plot ROC Curves\n",
    "    axes[1, 0].set_title('ROC Curve')\n",
    "    # CNN ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, cnn_predictions)\n",
    "    roc_auc = roc_auc_score(y_test, cnn_predictions)\n",
    "    axes[1, 0].plot(fpr, tpr, label=f'CNN (AUC = {roc_auc:.2f})')\n",
    "    # ResNet ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, resnet_predictions)\n",
    "    roc_auc = roc_auc_score(y_test, resnet_predictions)\n",
    "    axes[1, 0].plot(fpr, tpr, label=f'ResNet (AUC = {roc_auc:.2f})')\n",
    "    # PyTorch ResNet ROC\n",
    "    fpr, tpr, thresholds = roc_curve(pytorch_targets, pytorch_predictions)\n",
    "    roc_auc = roc_auc_score(pytorch_targets, pytorch_predictions)\n",
    "    axes[1, 0].plot(fpr, tpr, label=f'PyTorch ResNet (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "    axes[1, 0].set_xlim([0.0, 1.0])\n",
    "    axes[1, 0].set_ylim([0.0, 1.05])\n",
    "    axes[1, 0].set_xlabel('False Positive Rate')\n",
    "    axes[1, 0].set_ylabel('True Positive Rate')\n",
    "    axes[1, 0].legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot Confusion Matrices (example for CNN, can extend for others)\n",
    "    axes[1, 1].set_title('CNN Confusion Matrix')\n",
    "    sns.heatmap(confusion_matrix(y_test, cnn_pred_binary), annot=True, fmt='d', cmap='Blues', ax=axes[1, 1],\n",
    "                xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "    axes[1, 1].set_ylabel('Actual')\n",
    "    axes[1, 1].set_xlabel('Predicted')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Collect histories for plotting\n",
    "histories_to_plot = [cnn_history.history, resnet_history.history, pytorch_history]\n",
    "model_names_to_plot = ['CNN', 'ResNet', 'PyTorch ResNet']\n",
    "\n",
    "plot_training_history(histories_to_plot, model_names_to_plot)\n",
    "\n",
    "# Additionally, plot confusion matrices for all models\n",
    "print(\"\\n=== Confusion Matrices ===\")\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plot_confusion_matrix(y_test, cnn_pred_binary, title='CNN Confusion Matrix')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plot_confusion_matrix(y_test, resnet_pred_binary, title='ResNet Confusion Matrix')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plot_confusion_matrix(pytorch_targets, pytorch_pred_binary, title='PyTorch ResNet Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Best AUC score: {best_auc:.4f}\")\n",
    "print(\"All models and results have been saved to the models directory.\")\n",
    "\n",
    "# Optional: Memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Memory cleanup completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
